{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.regularizers import *\n",
    "from tensorflow.keras.constraints import unit_norm\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow.keras.backend as K\n",
    "import random\n",
    "import os\n",
    "import logmelspectr_params as params\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt_path = \"/nas/public/dataset/asvspoof2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\"\n",
    "train_feat_root = \"/nas/home/cborrelli/tripletloss_bot/features/logmelspectr/train\"\n",
    "df_train = pd.read_csv(train_txt_path, sep=\" \", header=None)\n",
    "df_train.columns = [\"speaker_id\", \"audio_filename\", \"null\", \"system_id\", \"label\"]\n",
    "df_train = df_train.drop(columns=\"null\")\n",
    "\n",
    "dev_txt_path = \"/nas/public/dataset/asvspoof2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt\"\n",
    "dev_feat_root = \"/nas/home/cborrelli/tripletloss_bot/features/logmelspectr/dev\"\n",
    "df_dev = pd.read_csv(dev_txt_path, sep=\" \", header=None)\n",
    "df_dev.columns = [\"speaker_id\", \"audio_filename\", \"null\", \"system_id\", \"label\"]\n",
    "df_dev = df_dev.drop(columns=\"null\")\n",
    "\n",
    "\n",
    "eval_txt_path = \"/nas/public/dataset/asvspoof2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt\"\n",
    "eval_feat_root = \"/nas/home/cborrelli/tripletloss_bot/features/logmelspectr/eval\"\n",
    "df_eval = pd.read_csv(eval_txt_path, sep=\" \", header=None)\n",
    "df_eval.columns = [\"speaker_id\", \"audio_filename\", \"null\", \"system_id\", \"label\"]\n",
    "df_eval = df_eval.drop(columns=\"null\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame(data, window_length, hop_length):\n",
    "    \"\"\"Convert array into a sequence of successive possibly overlapping frames.\n",
    "    An n-dimensional array of shape (num_samples, ...) is converted into an\n",
    "    (n+1)-D array of shape (num_frames, window_length, ...), where each frame\n",
    "    starts hop_length points after the preceding one.\n",
    "    This is accomplished using stride_tricks, so the original data is not\n",
    "    copied.  However, there is no zero-padding, so any incomplete frames at the\n",
    "    end are not included.\n",
    "    Args:\n",
    "    data: np.array of dimension N >= 1.\n",
    "    window_length: Number of samples in each frame.\n",
    "    hop_length: Advance (in samples) between each window.\n",
    "    Returns:\n",
    "    (N+1)-D np.array with as many rows as there are complete frames that can be\n",
    "    extracted.\n",
    "    \"\"\"\n",
    "    num_samples = data.shape[0]\n",
    "    num_frames = 1 + int(np.floor((num_samples - window_length) / hop_length))\n",
    "    shape = (num_frames, window_length) + data.shape[1:]\n",
    "    strides = (data.strides[0] * hop_length,) + data.strides\n",
    "    result = np.lib.stride_tricks.as_strided(data, shape=shape, strides=strides)\n",
    "    return result\n",
    "\n",
    "class TrainDataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    \n",
    "    def __init__(self, dataframe, feature_path, batch_size=32, dim=(96, 64), n_channels=1,\n",
    "                  shuffle=True, classes_list=['-', 'A01', 'A02', 'A03', 'A04', 'A05', 'A06'],\n",
    "                num_batch_epoch=100):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.dataframe = dataframe\n",
    "        self.classes_list = classes_list\n",
    "        self.n_channels = n_channels\n",
    "        self.len = num_batch_epoch\n",
    "        self.feature_path = feature_path\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, batch_index):\n",
    "        'Generate one batch of data'        \n",
    "        negative_couples_classes = np.array(list(itertools.combinations(self.classes_list, r=2)))\n",
    "        positive_couples_classes = np.array(list(zip(self.classes_list, self.classes_list)))\n",
    "\n",
    "        negative_selected_pairs = negative_couples_classes[np.random.choice(negative_couples_classes.shape[0], \n",
    "                                                            self.batch_size // 2, replace=True), :]\n",
    "        positive_selected_pairs = positive_couples_classes[np.random.choice(positive_couples_classes.shape[0], \n",
    "                                                            self.batch_size // 2, replace=True), :]\n",
    "\n",
    "        selected_pairs = np.concatenate((positive_selected_pairs, negative_selected_pairs), axis=0)\n",
    "\n",
    "        y = np.concatenate((np.zeros((self.batch_size//2)), np.ones((self.batch_size//2))), axis=0)\n",
    "\n",
    "        features_sample_rate = 1.0 / params.STFT_HOP_LENGTH_SECONDS\n",
    "\n",
    "        example_window_length = int(round(\n",
    "            params.EXAMPLE_WINDOW_SECONDS * features_sample_rate))\n",
    "        example_hop_length = int(round(\n",
    "            params.EXAMPLE_HOP_SECONDS * features_sample_rate))\n",
    "\n",
    "        X_0 = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        X_1 = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "\n",
    "        for sample_batch_index, pairs in enumerate(selected_pairs):\n",
    "\n",
    "            sample = np.empty((2, *self.dim, self.n_channels))\n",
    "            for a, alg in enumerate(pairs):\n",
    "                row = self.dataframe[self.dataframe.system_id == alg].sample(n=1)\n",
    "                log_mel = np.load(os.path.join(self.feature_path, row['audio_filename'].values[0] + '.npy'))\n",
    "                log_mel = log_mel.transpose()\n",
    "\n",
    "                if log_mel.shape[0] < self.dim[0]:\n",
    "                    pad_len = self.dim[0] - log_mel.shape[0] + 1\n",
    "                    log_mel = np.pad(log_mel, ((0, pad_len), (0, 0)))\n",
    "\n",
    "                log_mel = frame(log_mel, example_window_length, example_hop_length)\n",
    "\n",
    "                selected_frame = np.random.randint(low=0, high=log_mel.shape[0], size=1)\n",
    "\n",
    "                selected_log_mel = log_mel[selected_frame, :, :]\n",
    "                selected_log_mel = selected_log_mel[0,:, :, np.newaxis]\n",
    "\n",
    "                sample[a] = selected_log_mel\n",
    "\n",
    "            X_0[sample_batch_index] = sample[0]            \n",
    "            X_1[sample_batch_index] = sample[1]            \n",
    "\n",
    "\n",
    "        return [X_0, X_1], y\n",
    "\n",
    "    \n",
    "    \n",
    "class TestDataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    \n",
    "    def __init__(self, dataframe, feature_path, batch_size=32, dim=(96, 64), n_channels=1,\n",
    "                  shuffle=True, classes_pair=['-', '-'],\n",
    "                num_batch_epoch=100):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.dataframe = dataframe\n",
    "        self.n_channels = n_channels\n",
    "        self.len = num_batch_epoch\n",
    "        self.feature_path = feature_path\n",
    "        self.classes_pair = classes_pair\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, batch_index):\n",
    "        'Generate one batch of data'        \n",
    "\n",
    "            # If i am specifying only one element it means I want to use the data generator for testing\n",
    "            # only one class\n",
    "        \n",
    "        selected_pairs =  [self.classes_pair] * self.batch_size\n",
    "        features_sample_rate = 1.0 / params.STFT_HOP_LENGTH_SECONDS\n",
    "        example_window_length = int(round(\n",
    "            params.EXAMPLE_WINDOW_SECONDS * features_sample_rate))\n",
    "        example_hop_length = int(round(\n",
    "            params.EXAMPLE_HOP_SECONDS * features_sample_rate))\n",
    "\n",
    "        X_0 = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        X_1 = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        \n",
    "        if self.classes_pair[0] == self.classes_pair[1]:\n",
    "            y = np.zeros((self.batch_size))\n",
    "        else:\n",
    "            y = np.ones((self.batch_size))\n",
    "            \n",
    "        for sample_batch_index, pairs in enumerate(selected_pairs):\n",
    "\n",
    "            sample = np.empty((2, *self.dim, self.n_channels))\n",
    "            for a, alg in enumerate(pairs):\n",
    "                row = self.dataframe[self.dataframe.system_id == alg].sample(n=1)\n",
    "                log_mel = np.load(os.path.join(self.feature_path, row['audio_filename'].values[0] + '.npy'))\n",
    "                log_mel = log_mel.transpose()\n",
    "\n",
    "                if log_mel.shape[0] < self.dim[0]:\n",
    "                    pad_len = self.dim[0] - log_mel.shape[0] + 1\n",
    "                    log_mel = np.pad(log_mel, ((0, pad_len), (0, 0)))\n",
    "\n",
    "                log_mel = frame(log_mel, example_window_length, example_hop_length)\n",
    "\n",
    "                selected_frame = np.random.randint(low=0, high=log_mel.shape[0], size=1)\n",
    "\n",
    "                selected_log_mel = log_mel[selected_frame, :, :]\n",
    "                selected_log_mel = selected_log_mel[0,:, :, np.newaxis]\n",
    "\n",
    "                sample[a] = selected_log_mel\n",
    "\n",
    "            X_0[sample_batch_index] = sample[0]            \n",
    "            X_1[sample_batch_index] = sample[1]   \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        return [X_0, X_1], y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gombru.github.io/2019/04/03/ranking_loss/\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    return K.mean((1 - y_true) * K.square(y_pred) + (y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=-1, keepdims=True), K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('/nas/home/cborrelli/tripletloss_bot/checkpoints/siamese',  \n",
    "                   custom_objects={'contrastive_loss': contrastive_loss, \n",
    "                                   'euclidean_distance':euclidean_distance})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_generator = TestDataGenerator(dataframe=df_dev, feature_path=dev_feat_root, classes_pair=['A07', 'A01'])\n",
    "test_generator = TestDataGenerator(dataframe=df_eval, feature_path=eval_feat_root, classes_pair=['A08', 'A13'])\n",
    "predicted_diff = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_generator = TestDataGenerator(dataframe=df_dev, feature_path=dev_feat_root, classes_pair=['A01', 'A01'])\n",
    "test_generator = TestDataGenerator(dataframe=df_eval, feature_path=eval_feat_root, classes_pair=['A08', 'A08'])\n",
    "predicted_same = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predicted_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.displot(predicted_same, kind='hist', kde=True)\n",
    "sns.displot(predicted_diff, kind='hist', kde=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
